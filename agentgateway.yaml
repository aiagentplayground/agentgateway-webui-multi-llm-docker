# yaml-language-server: $schema=../../schema/local.json
config:
  adminAddr: "0.0.0.0:15000"
  tracing:
    otlpEndpoint: http://jaeger:4317
    randomSampling: true

binds:
# Main unified gateway - all providers accessible through one port
- port: 3000
  listeners:
  - name: agentgateway
    routes:
    # Anthropic AI backend with security & cost controls
    - name: anthropic-claude
      matches:
        - path:
            pathPrefix: /anthropic
      policies:
        # Cost Control: Rate limiting to prevent excessive API usage
        # Token bucket: 10 requests max, refill 10 tokens every 60 seconds
        localRateLimit:
          - maxTokens: 10
            tokensPerFill: 10
            fillInterval: 60s
        # Authentication: Secure API key handling
        backendAuth:
          key: "$ANTHROPIC_API_KEY"
      backends:
      - ai:
          name: anthropic
          provider:
            anthropic:
              model: claude-haiku-4-5-20251001
          routes:
            /v1/messages: messages
            /v1/chat/completions: completions
            /v1/models: passthrough
            "*": passthrough

    # OpenAI backend
    - name: openai-gpt
      matches:
        - path:
            pathPrefix: /openai
      policies:
        localRateLimit:
          - maxTokens: 10
            tokensPerFill: 10
            fillInterval: 60s
        backendAuth:
          key: "$OPENAI_API_KEY"
      backends:
      - ai:
          name: openai
          provider:
            openAI:
              model: gpt-5.2-2025-12-11
          routes:
            /openai/v1/chat/completions: completions
            /openai/v1/models: models

    # Gemini (Google AI)
    - name: google-gemini
      matches:
        - path:
            pathPrefix: /gemini
      policies:
        localRateLimit:
          - maxTokens: 10
            tokensPerFill: 10
            fillInterval: 60s
        backendAuth:
          key: "$GEMINI_API_KEY"
      backends:
      - ai:
          name: gemini
          provider:
            gemini:
              model: gemini-3-pro-preview
          routes:
            /gemini/v1/chat/completions: completions
            /gemini/v1/models: models

    # XAI Grok - OpenAI-compatible API
    - name: xai-grok
      matches:
        - path:
            pathPrefix: /xai
      policies:
        urlRewrite:
          authority:
            full: api.x.ai
          path:
            full: "/v1/chat/completions"
        backendTLS: {}
        localRateLimit:
          - maxTokens: 10
            tokensPerFill: 10
            fillInterval: 60s
        backendAuth:
          key: "$XAI_API_KEY"
      backends:
      - ai:
          name: xai
          hostOverride: api.x.ai:443
          provider:
            openAI:
              model: grok-4-latest
          routes:
            /xai/v1/chat/completions: completions

    # Hello Agent A2A
    - name: a2a-hello-agent
      matches:
        - path:
            pathPrefix: /agent/hello
      policies:
        cors:
          allowOrigins:
            - "*"
          allowHeaders:
            - "*"
        a2a: {}
      backends:
      - host: hello-agent:9001

    # Calculator Agent A2A
    - name: a2a-calculator-agent
      matches:
        - path:
            pathPrefix: /agent/calculator
      policies:
        cors:
          allowOrigins:
            - "*"
          allowHeaders:
            - "*"
        a2a: {}
      backends:
      - host: calculator-agent:9002

# Dedicated listener for Anthropic Claude
- port: 3001
  listeners:
  - name: anthropic-listener
    routes:
    - name: anthropic-direct
      policies:
        localRateLimit:
          - maxTokens: 10
            tokensPerFill: 10
            fillInterval: 60s
        backendAuth:
          key: "$ANTHROPIC_API_KEY"
      backends:
      - ai:
          name: anthropic
          provider:
            anthropic:
              model: claude-haiku-4-5-20251001
          routes:
            /v1/messages: messages
            /v1/chat/completions: completions
            /v1/models: passthrough
            "*": passthrough

# Dedicated listener for OpenAI
- port: 3002
  listeners:
  - name: openai-listener
    routes:
    - name: openai-direct
      policies:
        localRateLimit:
          - maxTokens: 10
            tokensPerFill: 10
            fillInterval: 60s
        backendAuth:
          key: "$OPENAI_API_KEY"
      backends:
      - ai:
          name: openai
          provider:
            openAI:
              model: gpt-5.2-2025-12-11
          routes:
            /v1/chat/completions: completions
            /v1/models: models

# Dedicated listener for xAI Grok
- port: 3003
  listeners:
  - name: xai-listener
    routes:
    - name: xai-direct
      policies:
        urlRewrite:
          authority:
            full: api.x.ai
          path:
            full: "/v1/chat/completions"
        backendTLS: {}
        localRateLimit:
          - maxTokens: 10
            tokensPerFill: 10
            fillInterval: 60s
        backendAuth:
          key: "$XAI_API_KEY"
      backends:
      - ai:
          name: xai
          hostOverride: api.x.ai:443
          provider:
            openAI:
              model: grok-4-latest
          routes:
            /v1/chat/completions: completions
            /v1/models: models

# Dedicated listener for Google Gemini
- port: 3004
  listeners:
  - name: gemini-listener
    routes:
    - name: gemini-direct
      policies:
        localRateLimit:
          - maxTokens: 10
            tokensPerFill: 10
            fillInterval: 60s
        backendAuth:
          key: "$GEMINI_API_KEY"
      backends:
      - ai:
          name: gemini
          provider:
            gemini:
              model: gemini-3-pro-preview
          routes:
            /v1/chat/completions: completions
            /v1/models: models

# Dedicated listener for MCP tools
- port: 3005
  listeners:
  - name: mcp-listener
    routes:
    - name: mcp-direct
      policies:
        cors:
          allowOrigins:
            - "*"
          allowHeaders:
            - mcp-protocol-version
            - content-type
            - cache-control
      backends:
      - mcp:
          targets:
          - name: everything
            stdio:
              cmd: npx
              args: ["@modelcontextprotocol/server-everything"]

# Dedicated listener for A2A agents
- port: 3006
  listeners:
  - name: a2a-listener
    routes:
    # Hello Agent
    - name: hello-agent-direct
      matches:
        - path:
            pathPrefix: /hello
      policies:
        cors:
          allowOrigins:
            - "*"
          allowHeaders:
            - "*"
        a2a: {}
      backends:
      - host: hello-agent:9001

    # Calculator Agent
    - name: calculator-agent-direct
      matches:
        - path:
            pathPrefix: /calculator
      policies:
        cors:
          allowOrigins:
            - "*"
          allowHeaders:
            - "*"
        a2a: {}
      backends:
      - host: calculator-agent:9002
